<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <meta charset="utf-8" />
    <meta name="generator" content="pandoc" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=yes"
    />
    <title>data_transport</title>
    <style type="text/css">
      code {
        white-space: pre-wrap;
      }
      span.smallcaps {
        font-variant: small-caps;
      }
      span.underline {
        text-decoration: underline;
      }
      div.column {
        display: inline-block;
        vertical-align: top;
        width: 50%;
      }
    </style>
  </head>
  <body>
    <h2 id="what">What</h2>
    <p>
      The Data Transport Tests are meant to validate your agent’s data transport
      layer (the part of the code that sends requests to the collector and
      interprets the responses). These tests are meant to be consumable both by
      code (for automated tests) and by humans, such that we can treat these
      tests as a sort of spec for agent-collector communication.
    </p>
    <p>
      The basic gist is that each of these tests are just collections of steps.
      A step is one of the following:
    </p>
    <ul>
      <li>
        An event that you need to induce your agent to do (such as generate a
        metric or do a harvest).
      </li>
      <li>
        An expectation that your agent should send a request (as a result of
        previous steps).
      </li>
      <li>
        A composite step, which is just several other steps grouped together to
        reduce repetition.
      </li>
    </ul>
    <h3 id="types-of-steps-not-an-exhaustive-list">
      Types of steps (not an exhaustive list)
    </h3>
    <ul>
      <li>
        <code>event_agent_start</code> – Represents the startup of the agent.
        Will contain a <code>payload</code> property that defines the startup
        configuration.
      </li>
      <li>
        <code>event_metric</code> – Represents some event that would cause your
        agent to generate a metric (such as a page view, a database query, etc).
      </li>
      <li>
        <code>event_harvest_metrics</code> – Represents some event that would
        cause your agent to harvest metrics (such as a harvest timer elapsing).
      </li>
      <li>
        <code>event_local_config_update</code> – Represents a change to local
        config while the agent is running.
      </li>
      <li>
        <code>expect_request</code> – Represents an expectation that a
        particular request should happen as a result of the previous events.
        <ul>
          <li>
            Will sometimes contain a <code>payload</code> property that defines
            the expected serialized payload (if omitted, payload can be
            ignored).
            <ul>
              <li>
                Expected payloads will sometimes contain wildcard tokens such as
                <code>"__ANY_FLOAT__"</code>.
              </li>
            </ul>
          </li>
          <li>
            Will sometimes contain a <code>response_payload</code> property that
            defines the response that the test runner should give to the agent
            (if omitted, just send back any payload that makes your agent
            continue on happily).
          </li>
        </ul>
      </li>
      <li>
        <code>expect_no_request</code> – Represents an expectation that
        <strong>no</strong> request should happen as a result of the previous
        events.
        <em
          >Note that this expectation is redundant if your test runner follows
          that paradigm that every request that occurs must be explicitly called
          out by the test data.</em
        >
      </li>
    </ul>
    <h3 id="but-our-agent-doesnt-do-xyz">
      “But our agent doesn’t do <em>xyz</em>!”
    </h3>
    <p>
      It is inevitable that there will be conflicts in functionality between the
      various agents. As much as possible, these tests are written to be
      idealistically comprehensive – that is, covering all behavior that a
      perfectly functioning agent should follow – but flexible enough for agents
      to intentionally ignore components that either don’t apply or are not yet
      supported.
    </p>
    <p>Examples:</p>
    <ul>
      <li>
        <strong>Discrepancy:</strong> Agent does not send
        <code>agent_settings</code> command.
        <ul>
          <li>
            <strong>Solution:</strong> Ignore <code>expect_request</code> steps
            with <code>"agent_settings"</code> as the command name.
          </li>
        </ul>
      </li>
      <li>
        <strong>Discrepancy:</strong> Agent does not yet support custom events.
        <ul>
          <li>
            <strong>Solution:</strong> Ignore any test that contains a
            <code>event_custom_event</code> step.
          </li>
        </ul>
      </li>
      <li>
        <strong>Discrepancy:</strong> Agent request payloads looks significantly
        different than the expected payload due to special reasons X, Y, and Z.
        <ul>
          <li>
            <strong>Solution:</strong> Pre-process all expected payloads to make
            them match your agent’s goofy output.
          </li>
        </ul>
      </li>
    </ul>
  </body>
</html>
